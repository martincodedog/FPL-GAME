import streamlit as st
import pandas as pd
import requests
import numpy as np

st.set_page_config(page_title="FPL æ•¸æ“šæ±ºç®—çµ‚ç«¯", layout="wide")

# å¸¸æ•¸è¨­å®š
LEAGUE_ID = "1133270"
IGNORE_PLAYER = "Emil Chau"

# --- 1. API æ•¸æ“šç²å– ---
@st.cache_data(ttl=3600)
def get_league_members(league_id):
    url = f"https://fantasy.premierleague.com/api/leagues-classic/{league_id}/standings/"
    r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
    r.raise_for_status()
    return [p for p in r.json()['standings']['results'] if p['player_name'] != IGNORE_PLAYER]

@st.cache_data(ttl=3600)
def get_history_data(entry_id):
    url = f"https://fantasy.premierleague.com/api/entry/{entry_id}/history/"
    r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
    return r.json()['current']

# --- 2. æ•¸æ“šæ ¸å¿ƒè¨ˆç®— ---
st.title("ðŸ“Š FPL è¯è³½æ±ºç®—é æ¸¬çµ‚ç«¯")

try:
    members = get_league_members(LEAGUE_ID)
    
    with st.spinner("ç³»çµ±æ­£åœ¨åŸ·è¡Œæ•¸æ“šå»ºæ¨¡èˆ‡è¶¨å‹¢é ä¼°..."):
        all_data = []
        for m in members:
            history = get_history_data(m['entry'])
            for h in history:
                all_data.append({
                    "é€±æ•¸": h['event'],
                    "ç¶“ç†äºº": m['player_name'],
                    "ç›®å‰ç¸½åˆ†": h['total_points'],
                    "ç•¶é€±å¾—åˆ†": h['points']
                })

        full_df = pd.DataFrame(all_data)

        # è¼¸è´ç©åˆ†æ ¸å¿ƒé‚è¼¯ (Net Score * 2)
        def calculate_gl(group):
            n = len(group)
            total_pts = group['ç›®å‰ç¸½åˆ†'].sum()
            # å…¬å¼: (å€‹äººåˆ† * (n-1) - å…¶ä»–äººç¸½åˆ†å’Œ) * 2
            group['è¼¸è´ç©åˆ†'] = (group['ç›®å‰ç¸½åˆ†'] * (n - 1) - (total_pts - group['ç›®å‰ç¸½åˆ†'])) * 2
            return group

        full_df = full_df.groupby('é€±æ•¸', group_keys=False).apply(calculate_gl)
        max_gw = full_df['é€±æ•¸'].max()
        
        # --- é æ¸¬é‚è¼¯è¨ˆç®— ---
        prediction_list = []
        current_gw_data = full_df[full_df['é€±æ•¸'] == max_gw]
        
        for m_name in full_df['ç¶“ç†äºº'].unique():
            m_history = full_df[full_df['ç¶“ç†äºº'] == m_name].sort_values('é€±æ•¸')
            
            # è¶¨å‹¢åˆ†æžï¼šè¿‘ 5 é€±å¹³å‡è¡¨ç¾
            recent_avg = m_history.tail(5)['ç•¶é€±å¾—åˆ†'].mean()
            remaining_weeks = 38 - max_gw
            
            # é æ¸¬ GW38 ç¸½å¾—åˆ†
            pred_total_points = m_history['ç›®å‰ç¸½åˆ†'].iloc[-1] + (recent_avg * remaining_weeks)
            prediction_list.append({
                "ç¶“ç†äºº": m_name, 
                "é æ¸¬ç¸½åˆ†": int(pred_total_points),
                "è¿‘æœŸå‡åˆ†": int(recent_avg),
                "ç¸½åˆ†æ¨™æº–å·®": int(m_history['ç•¶é€±å¾—åˆ†'].std())
            })
        
        pred_df = pd.DataFrame(prediction_list)
        n_players = len(pred_df)
        total_pred_pts = pred_df['é æ¸¬ç¸½åˆ†'].sum()
        
        # è¨ˆç®—é æ¸¬çš„è¼¸è´ç©åˆ† (GW38)
        pred_df['é æ¸¬GW38è¼¸è´'] = (pred_df['é æ¸¬ç¸½åˆ†'] * (n_players - 1) - (total_pred_pts - pred_df['é æ¸¬ç¸½åˆ†'])) * 2
        pred_df['é æ¸¬GW38è¼¸è´'] = pred_df['é æ¸¬GW38è¼¸è´'].astype(int)

    # --- 3. é ‚éƒ¨çœ‹æ¿ (æŒ‡æ¨™å¡ç‰‡) ---
    top_current = current_gw_data.loc[current_gw_data['è¼¸è´ç©åˆ†'].idxmax()]
    top_predicted = pred_df.loc[pred_df['é æ¸¬GW38è¼¸è´'].idxmax()]

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ç•¶å‰æœ€é«˜è¼¸è´", f"{int(top_current['è¼¸è´ç©åˆ†'])} pts", f"ç”± {top_current['ç¶“ç†äºº']}")
    c2.metric("é æ¸¬è³½å­£æœ«æœ€é«˜è¼¸è´", f"{int(top_predicted['é æ¸¬GW38è¼¸è´'])} pts", f"ç”± {top_predicted['ç¶“ç†äºº']}")
    c3.metric("è¯è³½å¹³å‡æ³¢å‹• (Â±)", f"{int(current_gw_data['è¼¸è´ç©åˆ†'].abs().mean())}")
    c4.metric("å‰©é¤˜è³½äº‹é€±æ•¸", f"{38 - max_gw}")

    # --- 4. é æ¸¬æ¨¡åž‹èªªæ˜Ž (Markdown) ---
    with st.expander("ðŸ“ æŸ¥çœ‹é æ¸¬æ¨¡åž‹è¨ˆç®—èªªæ˜Ž"):
        st.markdown(f"""
        ### ðŸ”® ç¬¬ 38 é€±é æ¸¬æ¨¡åž‹ç®—æ³•
        æœ¬ç³»çµ±æŽ¡ç”¨**å‹•æ…‹åŠ æ¬Šè¶¨å‹¢æ³•**é€²è¡Œè³½å­£æœ«é æ¸¬ï¼Œè¨ˆç®—æ­¥é©Ÿå¦‚ä¸‹ï¼š
        1. **æ•¸æ“šåŸºæº–**ï¼šä»¥ç›®å‰ç¬¬ **{max_gw}** é€±çš„ç´¯ç©ç¸½åˆ†ç‚ºåŸºç¤Žã€‚
        2. **è¿‘æœŸè¶¨å‹¢**ï¼šè¨ˆç®—æ¯ä½çŽ©å®¶**æœ€è¿‘ 5 é€± (GW {max_gw-4} - GW {max_gw})** çš„å¹³å‡å¾—åˆ†ã€‚é€™èƒ½æ›´æº–ç¢ºåæ˜ çŽ©å®¶ç•¶å‰çš„çƒéšŠç‹€æ…‹ï¼ˆå¦‚è½‰æœƒç­–ç•¥ã€å‚·ç—…å½±éŸ¿ï¼‰ã€‚
        3. **æŽ¨ç®—å…¬å¼**ï¼š
           $$é æ¸¬ç¸½åˆ† = ç›®å‰ç´¯ç©ç¸½åˆ† + (è¿‘æœŸ 5 é€±å¹³å‡åˆ† \\times {38 - max_gw} \\text{ å‰©é¤˜é€±æ•¸})$$
        4. **è¼¸è´ç©åˆ†é‡æ–°å¹³è¡¡**ï¼šå°‡æ‰€æœ‰çŽ©å®¶çš„é æ¸¬ç¸½åˆ†æ”¾å…¥è¯è³½æ± ä¸­ï¼Œé‡æ–°è¨ˆç®—åŸºæ–¼ç¬¬ 38 é€±é æ¸¬ç¸½åˆ†çš„ **Net Score Ã— 2**ã€‚
        """)

    # --- 5. è©³ç´°æ•¸æ“šè¡¨æ ¼ ---
    st.markdown("---")
    display_df = current_gw_data[['ç¶“ç†äºº', 'ç›®å‰ç¸½åˆ†', 'è¼¸è´ç©åˆ†']].merge(
        pred_df[['ç¶“ç†äºº', 'é æ¸¬GW38è¼¸è´', 'è¿‘æœŸå‡åˆ†']], on='ç¶“ç†äºº'
    ).sort_values('ç›®å‰ç¸½åˆ†', ascending=False)
    
    display_df['è¼¸è´ç©åˆ†'] = display_df['è¼¸è´ç©åˆ†'].astype(int)

    st.header(f"ðŸ† ç©åˆ†çµç®—èˆ‡é ä¼° (æˆªæ­¢è‡³ GW {max_gw})")
    
    def color_gl(val):
        color = '#2ecc71' if val > 0 else '#e74c3c' if val < 0 else '#95a5a6'
        return f'color: {color}; font-weight: bold'

    st.dataframe(
        display_df.style.applymap(color_gl, subset=['è¼¸è´ç©åˆ†', 'é æ¸¬GW38è¼¸è´']),
        use_container_width=True, hide_index=True
    )

    # --- 6. è¶¨å‹¢åœ–è¡¨ ---
    st.markdown("---")
    st.header("ðŸ“ˆ è¯è³½è¼¸è´ç©åˆ†è¶¨å‹¢åœ–")
    chart_data = full_df.pivot(index='é€±æ•¸', columns='ç¶“ç†äºº', values='è¼¸è´ç©åˆ†')
    st.line_chart(chart_data)

    # --- 7. å°ˆæ¥­çµ±è¨ˆæ‘˜è¦ (åº•æ¬„) ---
    st.markdown("---")
    st.header("ðŸ“Š å°ˆæ¥­çµ±è¨ˆæ‘˜è¦ (Professional Summary Statistics)")
    
    stats_cols = st.columns(3)
    
    with stats_cols[0]:
        st.subheader("ðŸ“Œ ç©©å®šåº¦åˆ†æž")
        # åˆ†æ•¸æ¨™æº–å·®è¶Šå°ï¼Œè¶Šç©©å®š
        consistency_df = pred_df.sort_values("ç¸½åˆ†æ¨™æº–å·®").head(3)
        st.write("è¯è³½æœ€ç©©å¥ç¶“ç†äºº (Top 3):")
        for i, row in consistency_df.iterrows():
            st.write(f"- **{row['ç¶“ç†äºº']}** (æ³¢å‹•çŽ‡: Â±{row['ç¸½åˆ†æ¨™æº–å·®']})")

    with stats_cols[1]:
        st.subheader("âš¡ æˆé•·æ½›åŠ›")
        # é æ¸¬è¼¸è´ vs ç•¶å‰è¼¸è´ å·®è·æœ€å¤§çš„äºº
        current_gl_map = current_gw_data.set_index('ç¶“ç†äºº')['è¼¸è´ç©åˆ†']
        pred_df['æˆé•·å¹…åº¦'] = pred_df['é æ¸¬GW38è¼¸è´'] - pred_df['ç¶“ç†äºº'].map(current_gl_map)
        potential_df = pred_df.sort_values("æˆé•·å¹…åº¦", ascending=False).head(3)
        st.write("çœ‹æ¼²ç¶“ç†äºº (é æ¸¬å­£æœ«å™´ç™¼):")
        for i, row in potential_df.iterrows():
            st.write(f"- **{row['ç¶“ç†äºº']}** (é è¨ˆæˆé•·: +{int(row['æˆé•·å¹…åº¦'])} pts)")

    with stats_cols[2]:
        st.subheader("ðŸ“‰ é¢¨éšªé è­¦")
        # é æ¸¬è¼¸è´å¤§å¹…ä¸‹é™çš„äºº
        risk_df = pred_df.sort_values("æˆé•·å¹…åº¦", ascending=True).head(3)
        st.write("çœ‹è·Œç¶“ç†äºº (éœ€æ³¨æ„è¿‘æœŸé ¹å‹¢):")
        for i, row in risk_df.iterrows():
            st.write(f"- **{row['ç¶“ç†äºº']}** (é è¨ˆè¡°é€€: {int(row['æˆé•·å¹…åº¦'])} pts)")

except Exception as e:
    st.error(f"ç³»çµ±é‹è¡ŒéŒ¯èª¤: {e}")

st.caption(f"æ•¸æ“šæºï¼šFPL Official API | å·²è‡ªå‹•éŽæ¿¾éžè¯è³½æˆå“¡ï¼š{IGNORE_PLAYER}")
